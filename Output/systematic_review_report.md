# Systematic Review Report
**Generated:** 2026-01-17 21:45
**Research Question:** LLM vs SLMs on Agentic Tasks

---
**⚠️ IMPORTANT DISCLAIMER**

This report was generated by an automated AI-powered system (AutoPRISMA) for demonstration purposes only. All findings require expert validation and should NOT be used for publication, clinical decisions, or policy-making without thorough human review by qualified domain experts.
---

## 1. Introduction

This systematic review examined: LLM vs SLMs on Agentic Tasks

## 2. Methods

### 2.1 PICO Framework

- **Population:** Artificial intelligence models
- **Intervention:** Large Language Models (LLMs)
- **Comparator:** Small Language Models (SLMs)
- **Outcome:** Performance on agentic tasks
- **Study Types:** Comparative study, Meta-analysis

### 2.2 Search Strategy

Searches were conducted across 2 databases.

**Query 1:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 2:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 3:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 4:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 5:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 6:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 7:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 8:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 9:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 10:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 11:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 12:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 13:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 14:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 15:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 16:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 17:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 18:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 19:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 20:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 21:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 22:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 23:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 24:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 25:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 26:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 27:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 28:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 29:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 30:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 31:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 32:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 33:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 34:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 35:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 36:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 37:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 38:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 39:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 40:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 41:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 42:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 43:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 44:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 45:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 46:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 47:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 48:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 49:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 50:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 51:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 52:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 53:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 54:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 55:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 56:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 57:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 58:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 59:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 60:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 61:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 62:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 63:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 64:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 65:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 66:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 67:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 68:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 69:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 70:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 71:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 72:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 73:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 74:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 75:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 76:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 77:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 78:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 79:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 80:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 81:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 82:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 83:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 84:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 85:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 86:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 87:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 88:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 89:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 90:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 91:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 92:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 93:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

**Query 94:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 95:** ("Large Language Models" OR "LLMs") AND ("Small Language Models" OR "SLMs") AND (agentic tasks OR agency) AND (performance OR efficacy)

**Query 96:** cat:cs.CL AND (("Large Language Models" OR LLMs) AND ("Small Language Models" OR SLMs) AND (agentic tasks OR agency) AND (performance OR efficacy))

### 2.3 Screening Criteria

**Inclusion Criteria:**
- The study must focus on artificial intelligence models.
- The study must compare Large Language Models (LLMs) with Small Language Models (SLMs).
- The study must report performance metrics on agentic tasks for both LLMs and SLMs.
- The study design must be a comparative study or meta-analysis.
- The study must be published in English.

**Exclusion Criteria:**
- Studies that do not compare Large Language Models (LLMs) with Small Language Models (SLMs).
- Studies that focus on populations other than artificial intelligence models.
- Studies that do not report performance metrics on agentic tasks for both LLMs and SLMs.
- Editorials, letters to the editor, case reports, and reviews without original data.
- Animal studies or non-human model studies.
- Studies published in languages other than English.

## 3. Results

### 3.1 Study Selection

The search identified 1100 records. After removing 457 duplicates, 643 records were screened. Finally, 160 studies were included in the synthesis.

See PRISMA flow diagram for details.

### 3.2 Study Characteristics

- **Total studies:** 160

### 3.3 Synthesis of Findings

**Major Themes:**

No themes were identified.

## 4. Discussion

### 4.1 Research Gaps

Research gap analysis was not completed.

### 4.2 Limitations

- This review was conducted using automated methods and requires expert validation
- Full-text review was not conducted for all papers
- Quality assessment of individual studies was not performed
- Meta-analysis was not conducted

## 5. Conclusion

This systematic review synthesized 160 studies addressing llm vs slms on agentic tasks. The findings revealed 0 major themes and identified 0 research gaps. Further research is needed in the areas identified.

## 6. References

1. Humza Ashraf, S. Danish, Aris Leivadeas et al. (2025). Energy-Aware Code Generation with LLMs: Benchmarking Small vs. Large Language Models for Sustainable AI Programming. *Unknown Journal*.
2. Anandita Garg, Uma Gaba, Deepan Muthirayan et al. (2025). Emissions and Performance Trade-off Between Small and Large Language Models. *Unknown Journal*.
3. Weijie Hong, Yifan Wu, Lingzhe Zhang et al. (2025). CSLParser: A Collaborative Framework Using Small and Large Language Models for Log Parsing. *Unknown Journal*.
4. Mohammad Amin Zadenoori, Vincenzo De Martino, Jacek Dabrowski et al. (2025). Does Model Size Matter? A Comparison of Small and Large Language Models for Requirements Classification. *Unknown Journal*.
5. Wenxuan Zhang, Yue Deng, Bing-Quan Liu et al. (2023). Sentiment Analysis in the Era of Large Language Models: A Reality Check. *Unknown Journal*.
6. Beizhe Hu, Qiang Sheng, Juan Cao et al. (2023). Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection. *Unknown Journal*.
7. Xianyang Zhan, Agam Goyal, Yilun Chen et al. (2024). SLM-Mod: Small Language Models Surpass LLMs at Content Moderation. *Unknown Journal*.
8. Yice Zhang, Guangyu Xie, Hongling Xu et al. (2024). Distilling Fine-grained Sentiment Understanding from Large Language Models. *Unknown Journal*.
9. Ziyi Zhou, Xiaoming Zhang, Shenghan Tan et al. (2025). Collaborative Evolution: Multi-Round Learning Between Large and Small Language Models for Emergent Fake News Detection. *Unknown Journal*.
10. Sabine Felde, Rudiger Buchkremer, G. Chehab et al. (2025). Performance and Practical Considerations of Large and Small Language Models in Clinical Decision Support in Rheumatology. *Unknown Journal*.
11. Ioannis Kalamakis, Sotiria Liappi, Dimitrios Papakostas et al. (2025). Language Models for Disinformation Detection: To be Large or to be Small?. *Unknown Journal*.
12. Polaris Jhandi, Owais Kazi, Shreyas Subramanian et al. (2025). Small Language Models for Efficient Agentic Tool Calling: Outperforming Large Models with Targeted Fine-tuning. *Unknown Journal*.
13. Rahul Kavi, Jeevan Anne (2024). Improving Medical Abstract Classification Using PEFT-LoRA Fine-Tuned Large and Small Language Models. *Unknown Journal*.
14. Hong Jia, Shiya Fu, Feng Xia et al. (2025). Beyond Scale: Small Language Models are Comparable to GPT-4 in Mental Health Understanding. *Unknown Journal*.
15. Zhi-Hao Tan, Zihan Zhao, Hao-Yu Shi et al. (2025). Learnware of Language Models: Specialized Small Language Models Can Do Big. *Unknown Journal*.
16. Orlando Marquez Ayala, Patrice Bechard, Emily Chen et al. (2025). Fine-Tune an SLM or Prompt an LLM? The Case of Generating Low-Code Workflows. *arXiv*.
17. Yiqi Li, Yusheng Liao, Zhe Chen et al. (2025). DICE: Structured Reasoning in LLMs through SLM-Guided Chain-of-Thought Correction. *arXiv*.
18. Matteo Marengo, Jarod Lévy, Jean-Emmanuel Bibault (2024). Benchmarking LLMs and SLMs for patient reported outcomes. *arXiv*.
19. Lovedeep Gondara, Jonathan Simkin, Graham Sayle et al. (2025). Small or Large? Zero-Shot or Finetuned? Guiding Language Model Choice for Specialized Applications in Healthcare. *arXiv*.
20. Thanmay Jayakumar, Fauzan Farooqui, Luqman Farooqui (2023). Large Language Models are legal but they are not: Making the case for a powerful LegalLLM. *arXiv*.
21. Kazuki Kusama, Honglin Shu, Masanari Kondo et al. (2025). How Small is Enough? Empirical Evidence of Quantized Small Language Models for Automated Program Repair. *arXiv*.
22. Xin Gao, Qizhi Pei, Zinan Tang et al. (2025). A Strategic Coordination Framework of Small LLMs Matches Large LLMs in Data Synthesis. *arXiv*.
23. Humza Ashraf, S. Danish, Aris Leivadeas et al. (2025). Energy-Aware Code Generation with LLMs: Benchmarking Small vs. Large Language Models for Sustainable AI Programming. *Unknown Journal*.
24. Anandita Garg, Uma Gaba, Deepan Muthirayan et al. (2025). Emissions and Performance Trade-off Between Small and Large Language Models. *Unknown Journal*.
25. Weijie Hong, Yifan Wu, Lingzhe Zhang et al. (2025). CSLParser: A Collaborative Framework Using Small and Large Language Models for Log Parsing. *Unknown Journal*.
26. Mohammad Amin Zadenoori, Vincenzo De Martino, Jacek Dabrowski et al. (2025). Does Model Size Matter? A Comparison of Small and Large Language Models for Requirements Classification. *Unknown Journal*.
27. Wenxuan Zhang, Yue Deng, Bing-Quan Liu et al. (2023). Sentiment Analysis in the Era of Large Language Models: A Reality Check. *Unknown Journal*.
28. Beizhe Hu, Qiang Sheng, Juan Cao et al. (2023). Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection. *Unknown Journal*.
29. Xianyang Zhan, Agam Goyal, Yilun Chen et al. (2024). SLM-Mod: Small Language Models Surpass LLMs at Content Moderation. *Unknown Journal*.
30. Yice Zhang, Guangyu Xie, Hongling Xu et al. (2024). Distilling Fine-grained Sentiment Understanding from Large Language Models. *Unknown Journal*.
31. Ziyi Zhou, Xiaoming Zhang, Shenghan Tan et al. (2025). Collaborative Evolution: Multi-Round Learning Between Large and Small Language Models for Emergent Fake News Detection. *Unknown Journal*.
32. Sabine Felde, Rudiger Buchkremer, G. Chehab et al. (2025). Performance and Practical Considerations of Large and Small Language Models in Clinical Decision Support in Rheumatology. *Unknown Journal*.
33. Ioannis Kalamakis, Sotiria Liappi, Dimitrios Papakostas et al. (2025). Language Models for Disinformation Detection: To be Large or to be Small?. *Unknown Journal*.
34. Polaris Jhandi, Owais Kazi, Shreyas Subramanian et al. (2025). Small Language Models for Efficient Agentic Tool Calling: Outperforming Large Models with Targeted Fine-tuning. *Unknown Journal*.
35. Rahul Kavi, Jeevan Anne (2024). Improving Medical Abstract Classification Using PEFT-LoRA Fine-Tuned Large and Small Language Models. *Unknown Journal*.
36. Hong Jia, Shiya Fu, Feng Xia et al. (2025). Beyond Scale: Small Language Models are Comparable to GPT-4 in Mental Health Understanding. *Unknown Journal*.
37. Zhi-Hao Tan, Zihan Zhao, Hao-Yu Shi et al. (2025). Learnware of Language Models: Specialized Small Language Models Can Do Big. *Unknown Journal*.
38. Matteo Marengo, Jarod Lévy, Jean-Emmanuel Bibault (2024). Benchmarking LLMs and SLMs for patient reported outcomes. *arXiv*.
39. Lovedeep Gondara, Jonathan Simkin, Graham Sayle et al. (2025). Small or Large? Zero-Shot or Finetuned? Guiding Language Model Choice for Specialized Applications in Healthcare. *arXiv*.
40. Kazuki Kusama, Honglin Shu, Masanari Kondo et al. (2025). How Small is Enough? Empirical Evidence of Quantized Small Language Models for Automated Program Repair. *arXiv*.
41. Humza Ashraf, S. Danish, Aris Leivadeas et al. (2025). Energy-Aware Code Generation with LLMs: Benchmarking Small vs. Large Language Models for Sustainable AI Programming. *Unknown Journal*.
42. Anandita Garg, Uma Gaba, Deepan Muthirayan et al. (2025). Emissions and Performance Trade-off Between Small and Large Language Models. *Unknown Journal*.
43. Weijie Hong, Yifan Wu, Lingzhe Zhang et al. (2025). CSLParser: A Collaborative Framework Using Small and Large Language Models for Log Parsing. *Unknown Journal*.
44. Mohammad Amin Zadenoori, Vincenzo De Martino, Jacek Dabrowski et al. (2025). Does Model Size Matter? A Comparison of Small and Large Language Models for Requirements Classification. *Unknown Journal*.
45. Wenxuan Zhang, Yue Deng, Bing-Quan Liu et al. (2023). Sentiment Analysis in the Era of Large Language Models: A Reality Check. *Unknown Journal*.
46. Beizhe Hu, Qiang Sheng, Juan Cao et al. (2023). Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection. *Unknown Journal*.
47. Xianyang Zhan, Agam Goyal, Yilun Chen et al. (2024). SLM-Mod: Small Language Models Surpass LLMs at Content Moderation. *Unknown Journal*.
48. Yice Zhang, Guangyu Xie, Hongling Xu et al. (2024). Distilling Fine-grained Sentiment Understanding from Large Language Models. *Unknown Journal*.
49. Ziyi Zhou, Xiaoming Zhang, Shenghan Tan et al. (2025). Collaborative Evolution: Multi-Round Learning Between Large and Small Language Models for Emergent Fake News Detection. *Unknown Journal*.
50. Sabine Felde, Rudiger Buchkremer, G. Chehab et al. (2025). Performance and Practical Considerations of Large and Small Language Models in Clinical Decision Support in Rheumatology. *Unknown Journal*.
51. Ioannis Kalamakis, Sotiria Liappi, Dimitrios Papakostas et al. (2025). Language Models for Disinformation Detection: To be Large or to be Small?. *Unknown Journal*.
52. Polaris Jhandi, Owais Kazi, Shreyas Subramanian et al. (2025). Small Language Models for Efficient Agentic Tool Calling: Outperforming Large Models with Targeted Fine-tuning. *Unknown Journal*.
53. Hong Jia, Shiya Fu, Feng Xia et al. (2025). Beyond Scale: Small Language Models are Comparable to GPT-4 in Mental Health Understanding. *Unknown Journal*.
54. Zhi-Hao Tan, Zihan Zhao, Hao-Yu Shi et al. (2025). Learnware of Language Models: Specialized Small Language Models Can Do Big. *Unknown Journal*.
55. Orlando Marquez Ayala, Patrice Bechard, Emily Chen et al. (2025). Fine-Tune an SLM or Prompt an LLM? The Case of Generating Low-Code Workflows. *arXiv*.
56. Yiqi Li, Yusheng Liao, Zhe Chen et al. (2025). DICE: Structured Reasoning in LLMs through SLM-Guided Chain-of-Thought Correction. *arXiv*.
57. Matteo Marengo, Jarod Lévy, Jean-Emmanuel Bibault (2024). Benchmarking LLMs and SLMs for patient reported outcomes. *arXiv*.
58. Lovedeep Gondara, Jonathan Simkin, Graham Sayle et al. (2025). Small or Large? Zero-Shot or Finetuned? Guiding Language Model Choice for Specialized Applications in Healthcare. *arXiv*.
59. Thanmay Jayakumar, Fauzan Farooqui, Luqman Farooqui (2023). Large Language Models are legal but they are not: Making the case for a powerful LegalLLM. *arXiv*.
60. Kazuki Kusama, Honglin Shu, Masanari Kondo et al. (2025). How Small is Enough? Empirical Evidence of Quantized Small Language Models for Automated Program Repair. *arXiv*.
61. Xin Gao, Qizhi Pei, Zinan Tang et al. (2025). A Strategic Coordination Framework of Small LLMs Matches Large LLMs in Data Synthesis. *arXiv*.
62. Humza Ashraf, S. Danish, Aris Leivadeas et al. (2025). Energy-Aware Code Generation with LLMs: Benchmarking Small vs. Large Language Models for Sustainable AI Programming. *Unknown Journal*.
63. Anandita Garg, Uma Gaba, Deepan Muthirayan et al. (2025). Emissions and Performance Trade-off Between Small and Large Language Models. *Unknown Journal*.
64. Weijie Hong, Yifan Wu, Lingzhe Zhang et al. (2025). CSLParser: A Collaborative Framework Using Small and Large Language Models for Log Parsing. *Unknown Journal*.
65. Mohammad Amin Zadenoori, Vincenzo De Martino, Jacek Dabrowski et al. (2025). Does Model Size Matter? A Comparison of Small and Large Language Models for Requirements Classification. *Unknown Journal*.
66. Wenxuan Zhang, Yue Deng, Bing-Quan Liu et al. (2023). Sentiment Analysis in the Era of Large Language Models: A Reality Check. *Unknown Journal*.
67. Xianyang Zhan, Agam Goyal, Yilun Chen et al. (2024). SLM-Mod: Small Language Models Surpass LLMs at Content Moderation. *Unknown Journal*.
68. Yice Zhang, Guangyu Xie, Hongling Xu et al. (2024). Distilling Fine-grained Sentiment Understanding from Large Language Models. *Unknown Journal*.
69. Ziyi Zhou, Xiaoming Zhang, Shenghan Tan et al. (2025). Collaborative Evolution: Multi-Round Learning Between Large and Small Language Models for Emergent Fake News Detection. *Unknown Journal*.
70. Sabine Felde, Rudiger Buchkremer, G. Chehab et al. (2025). Performance and Practical Considerations of Large and Small Language Models in Clinical Decision Support in Rheumatology. *Unknown Journal*.
71. Ioannis Kalamakis, Sotiria Liappi, Dimitrios Papakostas et al. (2025). Language Models for Disinformation Detection: To be Large or to be Small?. *Unknown Journal*.
72. Polaris Jhandi, Owais Kazi, Shreyas Subramanian et al. (2025). Small Language Models for Efficient Agentic Tool Calling: Outperforming Large Models with Targeted Fine-tuning. *Unknown Journal*.
73. Rahul Kavi, Jeevan Anne (2024). Improving Medical Abstract Classification Using PEFT-LoRA Fine-Tuned Large and Small Language Models. *Unknown Journal*.
74. Hong Jia, Shiya Fu, Feng Xia et al. (2025). Beyond Scale: Small Language Models are Comparable to GPT-4 in Mental Health Understanding. *Unknown Journal*.
75. Yiqi Li, Yusheng Liao, Zhe Chen et al. (2025). DICE: Structured Reasoning in LLMs through SLM-Guided Chain-of-Thought Correction. *arXiv*.
76. Matteo Marengo, Jarod Lévy, Jean-Emmanuel Bibault (2024). Benchmarking LLMs and SLMs for patient reported outcomes. *arXiv*.
77. Lovedeep Gondara, Jonathan Simkin, Graham Sayle et al. (2025). Small or Large? Zero-Shot or Finetuned? Guiding Language Model Choice for Specialized Applications in Healthcare. *arXiv*.
78. Thanmay Jayakumar, Fauzan Farooqui, Luqman Farooqui (2023). Large Language Models are legal but they are not: Making the case for a powerful LegalLLM. *arXiv*.
79. Kazuki Kusama, Honglin Shu, Masanari Kondo et al. (2025). How Small is Enough? Empirical Evidence of Quantized Small Language Models for Automated Program Repair. *arXiv*.
80. Xin Gao, Qizhi Pei, Zinan Tang et al. (2025). A Strategic Coordination Framework of Small LLMs Matches Large LLMs in Data Synthesis. *arXiv*.
81. Humza Ashraf, S. Danish, Aris Leivadeas et al. (2025). Energy-Aware Code Generation with LLMs: Benchmarking Small vs. Large Language Models for Sustainable AI Programming. *Unknown Journal*.
82. Anandita Garg, Uma Gaba, Deepan Muthirayan et al. (2025). Emissions and Performance Trade-off Between Small and Large Language Models. *Unknown Journal*.
83. Weijie Hong, Yifan Wu, Lingzhe Zhang et al. (2025). CSLParser: A Collaborative Framework Using Small and Large Language Models for Log Parsing. *Unknown Journal*.
84. Mohammad Amin Zadenoori, Vincenzo De Martino, Jacek Dabrowski et al. (2025). Does Model Size Matter? A Comparison of Small and Large Language Models for Requirements Classification. *Unknown Journal*.
85. Wenxuan Zhang, Yue Deng, Bing-Quan Liu et al. (2023). Sentiment Analysis in the Era of Large Language Models: A Reality Check. *Unknown Journal*.
86. Beizhe Hu, Qiang Sheng, Juan Cao et al. (2023). Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection. *Unknown Journal*.
87. Xianyang Zhan, Agam Goyal, Yilun Chen et al. (2024). SLM-Mod: Small Language Models Surpass LLMs at Content Moderation. *Unknown Journal*.
88. Yice Zhang, Guangyu Xie, Hongling Xu et al. (2024). Distilling Fine-grained Sentiment Understanding from Large Language Models. *Unknown Journal*.
89. Ziyi Zhou, Xiaoming Zhang, Shenghan Tan et al. (2025). Collaborative Evolution: Multi-Round Learning Between Large and Small Language Models for Emergent Fake News Detection. *Unknown Journal*.
90. Sabine Felde, Rudiger Buchkremer, G. Chehab et al. (2025). Performance and Practical Considerations of Large and Small Language Models in Clinical Decision Support in Rheumatology. *Unknown Journal*.
91. Ioannis Kalamakis, Sotiria Liappi, Dimitrios Papakostas et al. (2025). Language Models for Disinformation Detection: To be Large or to be Small?. *Unknown Journal*.
92. Polaris Jhandi, Owais Kazi, Shreyas Subramanian et al. (2025). Small Language Models for Efficient Agentic Tool Calling: Outperforming Large Models with Targeted Fine-tuning. *Unknown Journal*.
93. Rahul Kavi, Jeevan Anne (2024). Improving Medical Abstract Classification Using PEFT-LoRA Fine-Tuned Large and Small Language Models. *Unknown Journal*.
94. Hong Jia, Shiya Fu, Feng Xia et al. (2025). Beyond Scale: Small Language Models are Comparable to GPT-4 in Mental Health Understanding. *Unknown Journal*.
95. Zhi-Hao Tan, Zihan Zhao, Hao-Yu Shi et al. (2025). Learnware of Language Models: Specialized Small Language Models Can Do Big. *Unknown Journal*.
96. Orlando Marquez Ayala, Patrice Bechard, Emily Chen et al. (2025). Fine-Tune an SLM or Prompt an LLM? The Case of Generating Low-Code Workflows. *arXiv*.
97. Yiqi Li, Yusheng Liao, Zhe Chen et al. (2025). DICE: Structured Reasoning in LLMs through SLM-Guided Chain-of-Thought Correction. *arXiv*.
98. Matteo Marengo, Jarod Lévy, Jean-Emmanuel Bibault (2024). Benchmarking LLMs and SLMs for patient reported outcomes. *arXiv*.
99. Lovedeep Gondara, Jonathan Simkin, Graham Sayle et al. (2025). Small or Large? Zero-Shot or Finetuned? Guiding Language Model Choice for Specialized Applications in Healthcare. *arXiv*.
100. Thanmay Jayakumar, Fauzan Farooqui, Luqman Farooqui (2023). Large Language Models are legal but they are not: Making the case for a powerful LegalLLM. *arXiv*.
101. Kazuki Kusama, Honglin Shu, Masanari Kondo et al. (2025). How Small is Enough? Empirical Evidence of Quantized Small Language Models for Automated Program Repair. *arXiv*.
102. Xin Gao, Qizhi Pei, Zinan Tang et al. (2025). A Strategic Coordination Framework of Small LLMs Matches Large LLMs in Data Synthesis. *arXiv*.
103. Humza Ashraf, S. Danish, Aris Leivadeas et al. (2025). Energy-Aware Code Generation with LLMs: Benchmarking Small vs. Large Language Models for Sustainable AI Programming. *Unknown Journal*.
104. Anandita Garg, Uma Gaba, Deepan Muthirayan et al. (2025). Emissions and Performance Trade-off Between Small and Large Language Models. *Unknown Journal*.
105. Weijie Hong, Yifan Wu, Lingzhe Zhang et al. (2025). CSLParser: A Collaborative Framework Using Small and Large Language Models for Log Parsing. *Unknown Journal*.
106. Mohammad Amin Zadenoori, Vincenzo De Martino, Jacek Dabrowski et al. (2025). Does Model Size Matter? A Comparison of Small and Large Language Models for Requirements Classification. *Unknown Journal*.
107. Wenxuan Zhang, Yue Deng, Bing-Quan Liu et al. (2023). Sentiment Analysis in the Era of Large Language Models: A Reality Check. *Unknown Journal*.
108. Beizhe Hu, Qiang Sheng, Juan Cao et al. (2023). Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection. *Unknown Journal*.
109. Xianyang Zhan, Agam Goyal, Yilun Chen et al. (2024). SLM-Mod: Small Language Models Surpass LLMs at Content Moderation. *Unknown Journal*.
110. Yice Zhang, Guangyu Xie, Hongling Xu et al. (2024). Distilling Fine-grained Sentiment Understanding from Large Language Models. *Unknown Journal*.
111. Ziyi Zhou, Xiaoming Zhang, Shenghan Tan et al. (2025). Collaborative Evolution: Multi-Round Learning Between Large and Small Language Models for Emergent Fake News Detection. *Unknown Journal*.
112. Sabine Felde, Rudiger Buchkremer, G. Chehab et al. (2025). Performance and Practical Considerations of Large and Small Language Models in Clinical Decision Support in Rheumatology. *Unknown Journal*.
113. Ioannis Kalamakis, Sotiria Liappi, Dimitrios Papakostas et al. (2025). Language Models for Disinformation Detection: To be Large or to be Small?. *Unknown Journal*.
114. Polaris Jhandi, Owais Kazi, Shreyas Subramanian et al. (2025). Small Language Models for Efficient Agentic Tool Calling: Outperforming Large Models with Targeted Fine-tuning. *Unknown Journal*.
115. Rahul Kavi, Jeevan Anne (2024). Improving Medical Abstract Classification Using PEFT-LoRA Fine-Tuned Large and Small Language Models. *Unknown Journal*.
116. Hong Jia, Shiya Fu, Feng Xia et al. (2025). Beyond Scale: Small Language Models are Comparable to GPT-4 in Mental Health Understanding. *Unknown Journal*.
117. Zhi-Hao Tan, Zihan Zhao, Hao-Yu Shi et al. (2025). Learnware of Language Models: Specialized Small Language Models Can Do Big. *Unknown Journal*.
118. Matteo Marengo, Jarod Lévy, Jean-Emmanuel Bibault (2024). Benchmarking LLMs and SLMs for patient reported outcomes. *arXiv*.
119. Lovedeep Gondara, Jonathan Simkin, Graham Sayle et al. (2025). Small or Large? Zero-Shot or Finetuned? Guiding Language Model Choice for Specialized Applications in Healthcare. *arXiv*.
120. Kazuki Kusama, Honglin Shu, Masanari Kondo et al. (2025). How Small is Enough? Empirical Evidence of Quantized Small Language Models for Automated Program Repair. *arXiv*.
121. Humza Ashraf, S. Danish, Aris Leivadeas et al. (2025). Energy-Aware Code Generation with LLMs: Benchmarking Small vs. Large Language Models for Sustainable AI Programming. *Unknown Journal*.
122. Anandita Garg, Uma Gaba, Deepan Muthirayan et al. (2025). Emissions and Performance Trade-off Between Small and Large Language Models. *Unknown Journal*.
123. Weijie Hong, Yifan Wu, Lingzhe Zhang et al. (2025). CSLParser: A Collaborative Framework Using Small and Large Language Models for Log Parsing. *Unknown Journal*.
124. Mohammad Amin Zadenoori, Vincenzo De Martino, Jacek Dabrowski et al. (2025). Does Model Size Matter? A Comparison of Small and Large Language Models for Requirements Classification. *Unknown Journal*.
125. Wenxuan Zhang, Yue Deng, Bing-Quan Liu et al. (2023). Sentiment Analysis in the Era of Large Language Models: A Reality Check. *Unknown Journal*.
126. Beizhe Hu, Qiang Sheng, Juan Cao et al. (2023). Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection. *Unknown Journal*.
127. Xianyang Zhan, Agam Goyal, Yilun Chen et al. (2024). SLM-Mod: Small Language Models Surpass LLMs at Content Moderation. *Unknown Journal*.
128. Yice Zhang, Guangyu Xie, Hongling Xu et al. (2024). Distilling Fine-grained Sentiment Understanding from Large Language Models. *Unknown Journal*.
129. Ziyi Zhou, Xiaoming Zhang, Shenghan Tan et al. (2025). Collaborative Evolution: Multi-Round Learning Between Large and Small Language Models for Emergent Fake News Detection. *Unknown Journal*.
130. Sabine Felde, Rudiger Buchkremer, G. Chehab et al. (2025). Performance and Practical Considerations of Large and Small Language Models in Clinical Decision Support in Rheumatology. *Unknown Journal*.
131. Ioannis Kalamakis, Sotiria Liappi, Dimitrios Papakostas et al. (2025). Language Models for Disinformation Detection: To be Large or to be Small?. *Unknown Journal*.
132. Polaris Jhandi, Owais Kazi, Shreyas Subramanian et al. (2025). Small Language Models for Efficient Agentic Tool Calling: Outperforming Large Models with Targeted Fine-tuning. *Unknown Journal*.
133. Hong Jia, Shiya Fu, Feng Xia et al. (2025). Beyond Scale: Small Language Models are Comparable to GPT-4 in Mental Health Understanding. *Unknown Journal*.
134. Zhi-Hao Tan, Zihan Zhao, Hao-Yu Shi et al. (2025). Learnware of Language Models: Specialized Small Language Models Can Do Big. *Unknown Journal*.
135. Orlando Marquez Ayala, Patrice Bechard, Emily Chen et al. (2025). Fine-Tune an SLM or Prompt an LLM? The Case of Generating Low-Code Workflows. *arXiv*.
136. Yiqi Li, Yusheng Liao, Zhe Chen et al. (2025). DICE: Structured Reasoning in LLMs through SLM-Guided Chain-of-Thought Correction. *arXiv*.
137. Matteo Marengo, Jarod Lévy, Jean-Emmanuel Bibault (2024). Benchmarking LLMs and SLMs for patient reported outcomes. *arXiv*.
138. Lovedeep Gondara, Jonathan Simkin, Graham Sayle et al. (2025). Small or Large? Zero-Shot or Finetuned? Guiding Language Model Choice for Specialized Applications in Healthcare. *arXiv*.
139. Thanmay Jayakumar, Fauzan Farooqui, Luqman Farooqui (2023). Large Language Models are legal but they are not: Making the case for a powerful LegalLLM. *arXiv*.
140. Kazuki Kusama, Honglin Shu, Masanari Kondo et al. (2025). How Small is Enough? Empirical Evidence of Quantized Small Language Models for Automated Program Repair. *arXiv*.
141. Xin Gao, Qizhi Pei, Zinan Tang et al. (2025). A Strategic Coordination Framework of Small LLMs Matches Large LLMs in Data Synthesis. *arXiv*.
142. Humza Ashraf, S. Danish, Aris Leivadeas et al. (2025). Energy-Aware Code Generation with LLMs: Benchmarking Small vs. Large Language Models for Sustainable AI Programming. *Unknown Journal*.
143. Anandita Garg, Uma Gaba, Deepan Muthirayan et al. (2025). Emissions and Performance Trade-off Between Small and Large Language Models. *Unknown Journal*.
144. Weijie Hong, Yifan Wu, Lingzhe Zhang et al. (2025). CSLParser: A Collaborative Framework Using Small and Large Language Models for Log Parsing. *Unknown Journal*.
145. Mohammad Amin Zadenoori, Vincenzo De Martino, Jacek Dabrowski et al. (2025). Does Model Size Matter? A Comparison of Small and Large Language Models for Requirements Classification. *Unknown Journal*.
146. Wenxuan Zhang, Yue Deng, Bing-Quan Liu et al. (2023). Sentiment Analysis in the Era of Large Language Models: A Reality Check. *Unknown Journal*.
147. Xianyang Zhan, Agam Goyal, Yilun Chen et al. (2024). SLM-Mod: Small Language Models Surpass LLMs at Content Moderation. *Unknown Journal*.
148. Yice Zhang, Guangyu Xie, Hongling Xu et al. (2024). Distilling Fine-grained Sentiment Understanding from Large Language Models. *Unknown Journal*.
149. Ziyi Zhou, Xiaoming Zhang, Shenghan Tan et al. (2025). Collaborative Evolution: Multi-Round Learning Between Large and Small Language Models for Emergent Fake News Detection. *Unknown Journal*.
150. Sabine Felde, Rudiger Buchkremer, G. Chehab et al. (2025). Performance and Practical Considerations of Large and Small Language Models in Clinical Decision Support in Rheumatology. *Unknown Journal*.
151. Ioannis Kalamakis, Sotiria Liappi, Dimitrios Papakostas et al. (2025). Language Models for Disinformation Detection: To be Large or to be Small?. *Unknown Journal*.
152. Polaris Jhandi, Owais Kazi, Shreyas Subramanian et al. (2025). Small Language Models for Efficient Agentic Tool Calling: Outperforming Large Models with Targeted Fine-tuning. *Unknown Journal*.
153. Rahul Kavi, Jeevan Anne (2024). Improving Medical Abstract Classification Using PEFT-LoRA Fine-Tuned Large and Small Language Models. *Unknown Journal*.
154. Hong Jia, Shiya Fu, Feng Xia et al. (2025). Beyond Scale: Small Language Models are Comparable to GPT-4 in Mental Health Understanding. *Unknown Journal*.
155. Yiqi Li, Yusheng Liao, Zhe Chen et al. (2025). DICE: Structured Reasoning in LLMs through SLM-Guided Chain-of-Thought Correction. *arXiv*.
156. Matteo Marengo, Jarod Lévy, Jean-Emmanuel Bibault (2024). Benchmarking LLMs and SLMs for patient reported outcomes. *arXiv*.
157. Lovedeep Gondara, Jonathan Simkin, Graham Sayle et al. (2025). Small or Large? Zero-Shot or Finetuned? Guiding Language Model Choice for Specialized Applications in Healthcare. *arXiv*.
158. Thanmay Jayakumar, Fauzan Farooqui, Luqman Farooqui (2023). Large Language Models are legal but they are not: Making the case for a powerful LegalLLM. *arXiv*.
159. Kazuki Kusama, Honglin Shu, Masanari Kondo et al. (2025). How Small is Enough? Empirical Evidence of Quantized Small Language Models for Automated Program Repair. *arXiv*.
160. Xin Gao, Qizhi Pei, Zinan Tang et al. (2025). A Strategic Coordination Framework of Small LLMs Matches Large LLMs in Data Synthesis. *arXiv*.
